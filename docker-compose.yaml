version: '3.9'
services:
  nginx:
    container_name: 'nginx-nest'
    build:
      context: ./nginx
      dockerfile: Dockerfile
    ports:
      - '80:80'
    depends_on:
      - web
    networks:
      - ticket
  web:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./src:/app/src
      - ./src/logs:/app/logs
      - ./images:/app/images
    depends_on:
      db:
        condition: service_healthy
        restart: true
      redis:
        condition: service_started
      rabbitmq:
        condition: service_healthy
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: '2'
          memory: '1000M'
    expose:
      - '3000'
    logging:
      driver: 'json-file'
    networks:
      - ticket

  redis:
    image: redis:7.2
    restart: always
    command: redis-server
    ports:
      - '6379:6379'
    volumes:
      - ./data/redis:/var/lib/redis
      - ./data/redis-config:/usr/local/etc/redis
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
    networks:
      - ticket

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: ticketing_db
    ports:
      - '5432:5432'
    volumes:
      - ./data/db:/var/lib/postgresql/data
    healthcheck:
      test:
        [
          'CMD-SHELL',
          'pg_isready -U postgres -d ticketing_db -h localhost -p 5432',
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    networks:
      - ticket

  cron:
    build:
      context: ./batchServer
      dockerfile: Dockerfile
    volumes:
      - ./batchServer/src:/batch/src
    depends_on:
      db:
        condition: service_healthy
        restart: true
      redis:
        condition: service_started
    networks:
      - ticket

  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - '5672:5672'
      - '15672:15672'
    environment:
      - RABBITMQ_DEFAULT_USER=sanghun
      - RABBITMQ_DEFAULT_PASS=sanghun
    healthcheck:
      test: ['CMD', 'rabbitmq-diagnostics', 'status']
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - ticket

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.11
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - http.host=0.0.0.0
      - transport.host=0.0.0.0
      - xpack.security.enabled=false
      - xpack.monitoring.enabled=false
      - cluster.name=elasticsearch
      - bootstrap.memory_lock=true
      - 'ES_JAVA_OPTS=-Xms1g -Xmx1g'
    volumes:
      - test_data:/usr/share/elasticsearch/data/
      - ./elk-config/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - '9200:9200'
      - '9300:9300'
    networks:
      - ticket

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.11
    container_name: kibana
    volumes:
      - ./elk-config/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
      - kb_data:/usr/share/kibana/data
    ports:
      - '5601:5601'
    networks:
      - ticket
    depends_on:
      - elasticsearch

  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.11
    container_name: logstash
    volumes:
      - ./elk-config/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./elk-config/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - '5044:5044'
    networks:
      - ticket
    depends_on:
      - elasticsearch
      - kibana

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.17.11
    container_name: filebeat
    volumes:
      - ./elk-config/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./src/logs:/usr/share/filebeat/logs:ro
    networks:
      - ticket
    depends_on:
      # - elasticsearch
      - logstash

networks:
  ticket:
    name: ticketingnetwork

volumes:
  test_data:
  kb_data:
  ls_data:
